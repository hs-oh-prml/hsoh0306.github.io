I"È9<h2 id="texture">Texture</h2>
<ul>
  <li>TextureëŠ” ì´ë¯¸ì§€ë¥¼ interest regionìœ¼ë¡œ ë‚˜ëˆ„ê³  ê·¸ëŸ° regionì„ classifyí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” featureë‹¤.</li>
  <li>TextureëŠ” ì´ë¯¸ì§€ì˜ color ë˜ëŠ” intensityì˜ ê³µê°„ì  ì •ë³´ë¥¼ ì œê³µí•œë‹¤.</li>
  <li>TextureëŠ” ì¸ì ‘ pixelë“¤ì˜ intensity levelì˜ ê³µê°„ ë¶„í¬ë¡œ íŠ¹ì§•ëœë‹¤.</li>
  <li>TextureëŠ” ì´ë¯¸ì§€ intensityì—ì„œ local variationì˜ ë°˜ë³µë˜ëŠ” patternì´ë‹¤. ë”°ë¼ì„œ pointì—ì„œ ì •ì˜ë  ìˆ˜ ì—†ë‹¤.</li>
</ul>

<h3 id="approach">Approach</h3>
<ol>
  <li>Structural: textureëŠ” ê·œì¹™ì ì´ê³  ë°˜ë³µì ì¸ primitive texelì˜ setì´ë‹¤.</li>
  <li>Statistical: textureëŠ” regionì—ì„œ intensity arrangementì˜ ì •ëŸ‰ì ì¸ measureì´ë‹¤. ì´ëŸ° ì¸¡ì •ì˜ ì§‘í•©ì„ feature vectorë¼ê³  ë¶€ë¥¸ë‹¤.</li>
  <li>Modeling: texture modeling ê¸°ìˆ ì€ íŠ¹ì • textureë¥¼ êµ¬ì¶•í•˜ëŠ” ëª¨ë¸ì„ í¬í•¨í•œë‹¤.</li>
</ol>

<h4 id="aspects-of-texture">Aspects of Texture</h4>
<ul>
  <li>Size/Granularity</li>
  <li>Directionality/Orientation</li>
  <li>Random or regular</li>
</ul>

<h4 id="structural-approach-to-texture">Structural Approach to Texture</h4>
<ul>
  <li>Texelì„ ì •ì˜í•´ì•¼í•¨
    <ul>
      <li>real imageì—ì„œ texelì„ ì •ì˜í•˜ê³  ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ì–´ë µê±°ë‚˜ ë¶ˆê°€ëŠ¥í•¨</li>
    </ul>
  </li>
</ul>

<h4 id="statistical-approach-to-texture">Statistical Approach to Texture</h4>
<ul>
  <li>gray-scale intensity(or color)ì—ì„œ í†µê³„ì  ì¸¡ì •ìœ¼ë¡œ textureë¥¼ characterizeí•œë‹¤.</li>
  <li>ì§ê´€ì ì´ì§€ ì•Šì§€ë§Œ, ëª¨ë“  ì´ë¯¸ì§€ì—ì„œ ì ìš©ì´ ê°€ëŠ¥í•˜ê³ , ì—°ì‚°ì´ íš¨ìœ¨ì ì´ë‹¤.</li>
  <li>classificationì´ë‚˜ segmentationì—ì„œë„ ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.</li>
</ul>

<h4 id="texture-analysis">Texture Analysis</h4>
<ul>
  <li>Texture segmentation
  ì´ë¯¸ì§€ ë‚´ì—ì„œ ë‹¤ì–‘í•œ texture regionì‚¬ì´ì˜ boundaryë¥¼ ìë™ìœ¼ë¡œ ê²°ì •</li>
  <li>Texture classification
  ì£¼ì–´ì§„ texture classë¡œ ì´ë¯¸ì§€ ë‚´ì˜ texture regionì„ identifying</li>
</ul>

<h2 id="simple-statistical-texture-measure">Simple Statistical Texture Measure</h2>

<h4 id="range">Range</h4>
<p>One of the simplest of the texture operator is the range or difference between maximum and minimum intensity values in a neighbor</p>

<p>ì¸ì ‘ pixelì‚¬ì´ì—ì„œ ìµœëŒ€ ê°’ê³¼ ìµœì†Œ ê°’ ì°¨ì´ ê³„ì‚°</p>
<ul>
  <li>The range operator converts the original image to one in which brightness represents texture</li>
</ul>

<h4 id="variance">Variance</h4>
<p>Another estimator of texture is the variance in neighborhood regions</p>

<p>ì¤‘ì‹¬ pixelê³¼ ì¸ì ‘ pixel ì‚¬ì´ì˜ ì°¨ì´ì˜ í•© ê³„ì‚°</p>

<ul>
  <li>This is the sum of the squares of the differences between the intensity of the central pixel and its neighbors</li>
</ul>

<h3 id="quantitative-texture-measures">Quantitative Texture Measures</h3>
<ol>
  <li>Local Binary Pattern(LBP)</li>
  <li>Gray Level Co-occurence(GLCM)</li>
</ol>

<h4 id="local-binary-patternlbp">Local Binary Pattern(LBP)</h4>
<ul>
  <li>For each pixel \(p\), create an 8-bit number \(b_1\) \(b_2\) \(b_3\) \(b_4\) \(b_5\) \(b_6\) \(b_7\) \(b_8\), where \(b_i = 0\) if neighbor \(i\) has value less than or equal to \(p\)â€™s value and 1 otherwise.</li>
  <li>Represent the texture in the image (or a region) by the histogram of these numbers</li>
</ul>

<p>ì¤‘ì‹¬ pixelê³¼ ì¸ì ‘ í”½ì…€ê°„ ëŒ€ì†Œ ë¹„êµí•˜ì—¬ 8-bitì— ì €ì¥ í¬ë©´ 1, ì‘ê±°ë‚˜ ê°™ìœ¼ë©´ 0ì„ í‘œê¸°</p>

<p>Rotation invariantí•˜ì—¬ 10 levelë¡œ í•˜ëŠ” ë°©ë²•ë„ ìˆìŒ</p>

<h4 id="gray-level-co-occurrenceglcm">Gray Level Co-occurrence(GLCM)</h4>
<ul>
  <li>The statistical measures described so far are easy to calculate, but do not provide any information about the repeating nature of texture.</li>
  <li>A gray level co-occurrence matrix(GLCM) contains information about the positions of pixels having similar gray level values.</li>
</ul>

<p>í†µê³„ì  ì¸¡ì •ì€ ê³„ì‚°ì´ ì‰½ì§€ë§Œ, ë°˜ë³µë˜ëŠ” texture ë³¸ì§ˆì— ëŒ€í•œ ì •ë³´ëŠ” ì œê³µí•˜ì§€ ì•ŠëŠ”ë‹¤.</p>

<p>GLCMì€ similar gray level valueë¥¼ ê°€ì§€ëŠ” pixelì˜ ì¢Œí‘œ ì •ë³´ë„ í¬í•¨í•œë‹¤.</p>

<p>A co-occurrence matrix is a two-dimensional array, P, in which both the rows and the columns represent a set of possible image values</p>

<ul>
  <li>
    <p>A GLCM \(P_d[i,j]\) is defined by first specifying a displacement vector \(d=(dx,dy)\) and counting all pairs of pixels separated by d having gray levels \(i\) and \(j\).</p>
  </li>
  <li>
    <p>The GLCM is defined by: \(P_d[i,j] = n_{ij}\)</p>

    <ul>
      <li>\(n_{ij}\) is the number of occurrences of the pixel values \((i,j)\) lying at distance \(d\) in the image</li>
      <li>The co-occurrence matrix \(P_d\)has dimension nÃ—n, where n is the number of gray levels in the image</li>
    </ul>
  </li>
</ul>

<p>displacement vector \(d=(dx,dy)\)ë¥¼ ì •ì˜í•˜ê³ , ëª¨ë“  pairë¥¼ countingí•œë‹¤.</p>

<h5 id="algorithm">Algorithm</h5>
<ol>
  <li>Count all pairs of pixels in which the first pixel has a value \(i\), and its matching pair displaced from the first pixel by d has a value of \(j\)</li>
  <li>This count is entered in the ith row and jth column of the matrix \(P_d[i,j]\)</li>
  <li>Note that \(P_d[i,j]\) is not symmetric, since the number of pairs of pixels having gray levels \([i,j]\) does not necessarily equal the number of pixel pairs having gray levels \([j,i]\)</li>
</ol>

<h4 id="normalized-glcm">Normalized GLCM</h4>
<p>The elements of \(P_d[i,j]\) can be normalized by dividing each entry by the total number of pixel pairs</p>
<ul>
  <li>
    <p>Normalized GLCM, \(N[i,j]\) is defined by:</p>

\[N[i,j]= {P[i,j] \over \sum_i \sum_j  P[i,j]}\]
  </li>
  <li>
    <p>It normalizes the co-occurrence values to lie between 0 and 1, and allows them to be thought of as probabilites</p>
  </li>
</ul>

<h4 id="numeric-features-of-glcm">Numeric Features of GLCM</h4>
<ul>
  <li>Gray level co-occurrence matrices capture properties of a texture but they are not directly useful for further analysis, such as the comparison of two textures</li>
  <li>Numeric features are computed from the occurrence matrix that can be used to represent the texture more compactly
    <ul>
      <li>Maximum probability</li>
      <li>Moments</li>
      <li>Contrast</li>
      <li>Homogeneity</li>
      <li>Entropy</li>
      <li>Correlation</li>
    </ul>
  </li>
</ul>

<h5 id="maximum-probability">Maximum Probability</h5>
<ul>
  <li>This is simply the largest entry in the matrix, and corresponds to the strongest response
    <ul>
      <li>This could be the maximum in any of the matrices or the maximum overall</li>
      <li>
\[C_m=\max_{i,j} P_d[i,j]\]
      </li>
    </ul>
  </li>
</ul>

<h5 id="moments">Moments</h5>
<ul>
  <li>The order k element difference moment can be defined as:
    <ul>
      <li>
\[MOM_k = \sum_i \sum_j (i-j)^k P_d[i,j]\]
      </li>
    </ul>
  </li>
  <li>This descriptor has small values in cases where the largest elements in \(P\) are along the principal diagonal. The opposite effect can be achieved using the inverse moment
    <ul>
      <li>
\[MOM_k = \sum_i \sum_j {P_d[i,j] \over (i-j)^k}, i \neq j\]
      </li>
    </ul>
  </li>
</ul>

<h5 id="contrast">Contrast</h5>
<ul>
  <li>
    <p>Contrast is a measure of the local variations present in an image</p>

    <ul>
      <li>
\[MOM_k = \sum_i \sum_j (i-j)^k P_d[i,j]^n\]
      </li>
      <li>If there is a large amount of variation in an image the P[i,j]â€™s will be concentrated away from the main diagonal and contrast will be high</li>
      <li>Typically, \(k=2\) and \(n=1\)</li>
    </ul>
  </li>
</ul>

<h5 id="homogeneity">Homogeneity</h5>
<ul>
  <li>A homogeneous image will result in a co-occurrence matrix with a combination of high and low \(P[i,j]\)â€™s
    <ul>
      <li>
\[C_h = \sum_i \sum_j {P_d{i,j} \over 1 + \|i-j\|}\]
      </li>
      <li>Where the range of gray levels is small, the P[i,j] will tend to be clustered around the main diagonal</li>
      <li>A heterogeneous image will result in an even spread of \(P[i,j]\)â€™s</li>
    </ul>
  </li>
</ul>

<h5 id="entrophy">Entrophy</h5>
<ul>
  <li>Entropy is a measure of information content</li>
  <li>It measures the randomness of intensity distribution
    <ul>
      <li>
\[C_e = - \sum_i \sum_j P_d[i, j]ln P_d[i,j]\]
      </li>
    </ul>
  </li>
  <li>Entropy is highest when all entries in \(P[i,j]\) are of similar magnitude, and small when the entries in \(P[i,j]\) are unequal</li>
</ul>

<h5 id="correlation">Correlation</h5>
<ul>
  <li>Correlation is a measure of image linearity
    <ul>
      <li>
\[C_e = {\sum_i \sum_j ij P_d[i,j] - \mu_i \mu_j \over \sigma_i \sigma_j}, \mu_i = \sum i P_d[i,j], \sigma_i^2= \sum i^2 P_d[i,j] - \mu_i^2\]
      </li>
    </ul>
  </li>
  <li>Correlation will be high if an image contains a considerable amount of linear structure</li>
</ul>

<h4 id="problem-with-glcm">Problem with GLCM</h4>
<ul>
  <li>
    <p>One problem with deriving texture measures from co-occurrence matrices is how to choose the displacement vector \(d\)</p>

    <ul>
      <li>The choice of the displacement vector is an important parameter in the definition of the GLCM</li>
      <li>Occasionally the GLCM is computed from several values of d and the one which maximizes a statistical measure computed from \(P[i,j]\) is used</li>
      <li>
        <p>Zucker and Terzopoulos used a \(\chi^2\) measure to select the values of d that have the most structure, i.e., to maximize the value</p>

        <ul>
          <li>
\[\chi^2(d)= \sum_i \sum_j {P_d^2[i,j] \over P_d[i] P_d[j]} - 1\]
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="edges-and-texture">Edges and Texture</h3>
<ul>
  <li>It should be possible to locate the edges that result from the intensity transitions along the boundary of the texture
    <ul>
      <li>Since a texture will have large numbers of texels, there should be a property of the edge pixels that can be used to characterize the texture</li>
    </ul>
  </li>
  <li>Compute the co-occurrence matrix of an edge-enhanced image</li>
  <li>Edge Density and Direction</li>
  <li>Use an edge detector as the first step in texture analysis</li>
  <li>The number of edge pixels in a fixed-size region tells us how busy that region is</li>
  <li>The directions of the edges also help characterize the texture</li>
</ul>

<h4 id="two-edge-based-texture-measures">Two Edge-based Texture Measures</h4>
<ol>
  <li>
    <p>Edgeness per unit area for a region R</p>

    <ul>
      <li>
\[Fedgeness = \|{ p \| gradient_magnitude(p) â‰¥ threshold} \| / N\]
      </li>
      <li>N is the size of the unit area</li>
    </ul>
  </li>
  <li>
    <p>Histograms of edge magnitude and direction for a region R</p>
    <ul>
      <li>
\[F_magdir = ( H_magnitude, H_direction )\]
      </li>
      <li>These are the normalized histograms of gradient magnitudes and gradient directions, respectively</li>
    </ul>
  </li>
</ol>

<h4 id="energy-and-texture">Energy and Texture</h4>
<ul>
  <li>One approach to generate texture features is to use local kernels to detect various types of texture</li>
  <li>Laws developed a texture-energy approach that measures the amount of variation within a fixed size window</li>
</ul>

<h4 id="laws-texture-energy">Lawâ€™s Texture Energy</h4>
<ul>
  <li>Filter the input image using texture filters</li>
  <li>Compute texture energy by summing the absolute value of filtering results in local neighborhoods around each pixel</li>
  <li>Combine features to achieve rotational invariance</li>
</ul>

<p>-A set of convolution mask are used to compute texture energy</p>
<ul>
  <li>The mask are computed from the following basic mask
    <ul>
      <li>L5 (Gaussian) gives a center-weighted local average
        <ul>
          <li>
\[L5 = [1,4,6,4,2]\]
          </li>
        </ul>
      </li>
      <li>E5 (gradient) responds to row or col step edges
        <ul>
          <li>
\[E5 = [-1,-2,0,2,1]\]
          </li>
        </ul>
      </li>
      <li>S5 (LoG) detectss spots
        <ul>
          <li>
\[S5 = [-1,0,2,0,-1]\]
          </li>
        </ul>
      </li>
      <li>R5 (Gabor) detects ripples
        <ul>
          <li>
\[R5 = [1,-4,6,-4,1]\]
          </li>
        </ul>
      </li>
      <li>W5(wave) detects waves
        <ul>
          <li>
\[W5 = [-1,2,0,-2,1]\]
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>The 2D convolution mask are obtained by computing the outer product of a pair of vectors
    <ul>
      <li>For example, E5L5 is computed as the product of E5 and L5 as follows</li>
    </ul>
  </li>
  <li>Bias from the â€œdirectionalityâ€ of textures can be removed by combining symmetric pairs of features, making them rotationally invariant
    <ul>
      <li>For example, S5L5 (H) + L5S5 (V) = L5S5R</li>
    </ul>
  </li>
  <li>After the convolution with the specified mask, the texture energy measure (TEM) is computed by summing the absolute values in a local neighborhood
    <ul>
      <li>
\[L_e = \sum_{i=1}^m \sum_{j=1}^n \|C(i,j)\|\]
      </li>
    </ul>
  </li>
  <li>If n masks are applied, the result is an n-dimensional feature vector at each pixel of the image being analyzed</li>
</ul>

<h4 id="algorithm-1">Algorithm</h4>
<ol>
  <li>Apply convolution masks</li>
  <li>Calculate the texture energy measure (TEM) at each pixel. This is achieved by summing the absolute values in a local neighborhood</li>
  <li>Normalize features â€“ use L5L5 to normalize the TEM image</li>
</ol>

<ul>
  <li>Subtract mean neighborhood intensity from pixel (to reduce illumination effects)</li>
  <li>Filter the neighborhood with 16 masks</li>
  <li>Compute energy at each pixel by summing absolute value of filter output across neighborhood around pixel</li>
  <li>Define 9 features as follows (replace each pair with average)</li>
  <li>L5E5 / E5L5, L5R5 / R5L5</li>
  <li>E5S5 / S5E5, L5S5 / S5L5</li>
  <li>E5R5 / R5E5, S5R5 / S5R5</li>
  <li>R5R5, S5S5, E5E5</li>
</ul>

<h3 id="autocorrelation-for-texture">Autocorrelation for texture</h3>
<ul>
  <li>Autocorrelation function computes the dot product (energy) of original image with shifted image for different shifts
    <ul>
      <li>
\[\rho (dr, dc) = {\sum_i \sum_j I[i, j]I[i+dr, j+dc] \over \sum_i \sum_j I^2[i, j]}= {I[i, j] \circ I_d[i ,j] \over I[i, j] \circ I[i, j]}\]
      </li>
    </ul>
  </li>
  <li>It can detect repetitive patterns of texels</li>
  <li>
    <p>Also it can captures fineness/coarseness of the texture</p>
  </li>
  <li>Regular textures : function will have peaks and valleys</li>
  <li>Random textures: only peak at [0,0] and breadth of peak gives the size of the texture</li>
  <li>Coarse texture: function drops off slowly</li>
  <li>Fine texture : function drops off rapidly</li>
  <li>Can drop differently for row and column</li>
</ul>
:ET