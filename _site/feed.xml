<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-10-04T22:10:29+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Develope Yourself</title><subtitle>Just Do It!
</subtitle><author><name>GitHub User</name><email>dhgudtjr0306@gmail.com</email></author><entry><title type="html">[AlexNet] ImageNet Classification with Deep Convolutional Neural Networks 리뷰</title><link href="http://localhost:4000/review/2020/09/26/alexnet.html" rel="alternate" type="text/html" title="[AlexNet] ImageNet Classification with Deep Convolutional Neural Networks 리뷰" /><published>2020-09-26T00:00:00+09:00</published><updated>2020-09-26T00:00:00+09:00</updated><id>http://localhost:4000/review/2020/09/26/alexnet</id><content type="html" xml:base="http://localhost:4000/review/2020/09/26/alexnet.html">&lt;h2 id=&quot;alexnet&quot;&gt;AlexNet&lt;/h2&gt;
&lt;p&gt;“ImageNet Classification with Deep Convolutional Neural Networks”의 저자 Alex Krizhevsky의 이름을 따서 network의  AlexNet이라는 명칭이 붙었다. ILSVRC-2012에서 top-5 test error를 15.3%를 기록 했으며, 26.2%었던 2등과 비교하여 무려 10%가 넘는 격차를 내고 우승했다. ReLU의 대유행을 만들어낸 의미 있는 모델이다.&lt;/p&gt;

&lt;h2 id=&quot;dataset&quot;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;ImageNet은 약 22000 가지의 class에 속하는 1500만개의 고해상도 이미지 데이터 셋이다. 데이터는 Amazon’s Mechanical Turk crowd-sourcing tool를 사용하여 사람이 labeling하여 수집된다고 한다. ILSVRC(ImageNet Large-Scale Visual Acception Challenge)에서는 ImageNet에서 약 1000장의 이미지를 가진 1000개의 class를 사용한다. 전체적으로 120만 장의 학습 이미지와 5만 장의 검증 이미지, 15만 장의 테스트 이미지가 있다. top-1과 top-5 error를 ImageNet에 보고하는데, 여기서 top-5 error는 모델이 가장 가능성이 높다고 출력한 5 개의 label에 대해서 정답이 없는 비율이다. 
ImageNet은 variable-resolution 이미지로 구성되지만, constant input dimensionality를 필요로 때문에, 이미지를 256x256으로 down sampling을 했다고 한다. 이미지를 자르는 작업 외에 다른 전처리를 하지않고, 픽셀의 R,G,B 원래의 값을 사용했다.&lt;/p&gt;

&lt;h2 id=&quot;alexnet-network-architecture&quot;&gt;AlexNet Network Architecture&lt;/h2&gt;
&lt;p&gt;네트워크는 5개의 convolutional layer와 3개의 fully-connected layer로 총 8개의 layer로 구성된다. 네트워크 설계에 사용된 4개의 큰 특징을 소개한다.&lt;/p&gt;

&lt;h3 id=&quot;relu-nonlinearity&quot;&gt;ReLU Nonlinearity&lt;/h3&gt;
&lt;p&gt;ReLU가 유행하기 전까지 활성화 함수는 tanh가 많이 사용됐다. 논문에서는 경사 하강법에서 saturating nonlinearities는 non-saturating nonlinearity보다 훨씬 느리다고 했다. saturating nonlinearities와 non-saturating nonlinearity가 뭔지 찾아보니&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f$ is non-saturating iff $(|\lim\limits_{z \to -\infty} f(z)|= +\infty)∨(|\lim\limits_{z \to \infty} f(z)|= +\infty)$ &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;$f$ is saturating iff $f$ is not non-saturating.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$f$가 무한으로 발산하면 non-saturating이고, 그렇지 않으면 saturating이란다. 즉, ReLU는 무한으로 발산하므로, non-saturating이고, [-1, 1] 수렴하는 tanh나 [0, 1]로 수렴하는 sigmoid는 saturating에 해당된다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Sigmoid&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;tanh&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ReLU&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/img/sigmoid.png&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/img/tanh.png&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/img/relu.png&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$sigmoid(x) = (1+e^{-x})^{-1}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$tanh(x) = (1-e^{-x})/(1+e^{-x})$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$ReLU(x) = max(0, x)$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Sigmoid와 tanh에 비해서 ReLU의 식이 단순한 것으로 보아, 연산 속도를 빠르게 한다는 것을 직관적으로 추론이 가능한데, 결과는 다음과 같다.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;/assets/img/alexnet_relu.png&quot; width=&quot;60%&quot; /&gt;
&lt;/center&gt;

&lt;p&gt;&lt;em&gt;Figure 1: A four-layer convolutional neural network with ReLUs (solid line) reaches a 25% training error rate on CIFAR-10 six times faster than an equivalent network with tanh neurons (dashed line). The learning rates for each network were chosen independently to make training as fast as possible. No regularization of any kind was employed. The magnitude of the effect demonstrated here varies with network architecture, but networks with ReLUs consistently learn several times faster than equivalents with saturating neurons.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;실선이 ReLU를 사용한 결과고, 점선은 tanh를 사용한 실험 결과다. 결과로 보았을 때, ReLU가 tanh를 사용했을 때보다 6배 이상 빠른 것을 알 수 있다. 이렇게 빨라진 속도는 대량의 학습 데이터를 사용하는 것을 가능하게 했다.&lt;/p&gt;

&lt;h3 id=&quot;training-on-multiple-gpu&quot;&gt;Training on Multiple GPU&lt;/h3&gt;
&lt;p&gt;저자는 실험을 위해 GTX 580 GPU를 2개를 사용했다고 한다. 120만개의 학습 데이터를 충분히 학습 시킬만한 크기의 네트워크를 로드하는데 3GB짜리 GPU하나로는 부족했다. 현대의 GPU는 호스트의 메모리를 통하지 않고, 다른 GPU로 직접 I/O를 할 수 있어 병렬화에 적합하다. 네트크를 반으로 분리하여 각 GPU에 로드하여, 학습을 진행한다. 특정 레이어에서는 각 GPU의 파라미터를 모두 받으며 통신을 했다고 한다. 이 방법을 통해서 top-1 error를 1.7%, top-5 error를 1.2% 감소시켰으며, 단일 GPU를 사용했을 때보다 학습시간을 더 단축시킬 수 있었다.&lt;/p&gt;

&lt;h3 id=&quot;local-response-normalization&quot;&gt;Local Response Normalization&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;ReLUs have the desirable property that they do not require input normalization to prevent them from saturating. If at least some training examples produce a positive input to a ReLU, learning will happen in that neuron. However, we still find that the following local normalization scheme aids generalization.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ReLU는 input에 대하여 nomalization이 필요 없고, Local Response Normalizaation은 generalization에 도움이 된다는 것을 발견했다고 한다. Local Response Normalizaation은 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;center&gt; $b_{x,y}^{i} = a_{x,y}^{i} / (k+\alpha \displaystyle\sum_{j=max(0,i-n/2)}^{min(N-1,i+n/2)} (a_{x,y}^j)^{2})^\beta$ &lt;/center&gt;
  &lt;p&gt;where&lt;br /&gt;
$b_{x,y}^{i}$ : regularized output for kernel $i$ at position $x, y$&lt;br /&gt;
$a_{x,y}^{i}$ : source output of kernel $i$ applied at position $x, y$&lt;br /&gt;
$N$ : total number of kernels&lt;br /&gt;
$n$ : size of normalization neigborhood&lt;br /&gt;
$\alpha, \beta, (n)$ : hyperparmeters&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;$a_{x,y}^{i}$는 input으로 $i$번째 kernel에서 $x, y$ 값을 의미하고, $b_{x,y}^{i}$는 output을 의미한다. 논문에서는 $k=2, n=5, \alpha=10^{-4}, \beta=0.75$로 설정하고, top-1 error를 1.4%, top-5 error를 1.2% 감소시키는 효과를 얻었다고 한다.&lt;/p&gt;

&lt;h3 id=&quot;overlapping-pooling&quot;&gt;Overlapping Pooling&lt;/h3&gt;
&lt;p&gt;전통적인 CNN에서는 non-overlapping pooling을 사용했지만, overlapping pooling을 통해 약간의 overfit을 개선하는데 효과를 봤다고 한다. overlapping pooling은 kernel의 크기보다 stride의 크기를 작게하면서 구현된다. kernel의 크기와 stride의 크기가 같은 경우 non-overlapping pooling이 된다. kernel의 크기보다, stride가 작게하여 시각화하면 다음과 같은 결과가 나온다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/overlapping_pooling.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;논문에서는 이 방법을 이용하여 top-1, top-5 error를 0.4%, 0.3% 감소시켰다고한다.&lt;/p&gt;

&lt;h3 id=&quot;architecture&quot;&gt;Architecture&lt;/h3&gt;

&lt;center&gt;
&lt;img src=&quot;/assets/img/alexnet.png&quot; width=&quot;100%&quot; /&gt;
&lt;/center&gt;

&lt;p&gt;&lt;em&gt;Figure 2: An illustration of the architecture of our CNN, explicitly showing the delineation of responsibilities between the two GPUs. One GPU runs the layer-parts at the top of the figure while the other runs the layer-parts at the bottom. The GPUs communicate only at certain layers. The network’s input is 150,528-dimensional, and the number of neurons in the network’s remaining layers is given by 253,440–186,624–64,896–64,896–43,264–4096–4096–1000.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;네트크는 5개의 convolution layer와 3개의 fully-connected layer로 구성된다. 마지막 fully-connected layer는 softmax를 통해 각 1000개의 class label에 대한 확률을 출력한다. 3번째 layer와 모든 fully-connected layer에서 GPU connection이 이루어져 parameter를 공유한다. Local Response Normalization은 첫번째와 두번째 layer에서 이루어진다. 첫번째와 두번째, 다섯번째 layer에서 max-pooling이 된다. ReLU는 모든 layer에 적용된다. 입력 이미지의 크기는 224x224x3이다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Convolution Layer 1&lt;/td&gt;
      &lt;td&gt;96x(11x11x3) kernels&lt;/td&gt;
      &lt;td&gt;Conv5x5, stride: 1 kernel: 256, padding: 2&lt;/td&gt;
      &lt;td&gt;ReLU&lt;/td&gt;
      &lt;td&gt;Overlapping Max pooling3x3, stride: 2&lt;/td&gt;
      &lt;td&gt;Local Response Normalization&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Convolution Layer 2&lt;/td&gt;
      &lt;td&gt;256x(5x5x48) kernels&lt;/td&gt;
      &lt;td&gt;Conv3x3, stride: 1 kernel: 384, padding: 1&lt;/td&gt;
      &lt;td&gt;ReLU&lt;/td&gt;
      &lt;td&gt;Overlapping Max pooling3x3, stride: 2&lt;/td&gt;
      &lt;td&gt;Local Response Normalization&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Convolution Layer 3&lt;/td&gt;
      &lt;td&gt;384x(3x3x256) kernels&lt;/td&gt;
      &lt;td&gt;Conv3x3, stride: 1 kernel: 384, padding: 1&lt;/td&gt;
      &lt;td&gt;ReLU&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;GPU Connection&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Convolution Layer 4&lt;/td&gt;
      &lt;td&gt;384x(3x3x192) kernels&lt;/td&gt;
      &lt;td&gt;Conv3x3, stride: 1 kernel: 384, padding: 1&lt;/td&gt;
      &lt;td&gt;ReLU&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Convolution Layer 5&lt;/td&gt;
      &lt;td&gt;256x(3x3x192) kernels&lt;/td&gt;
      &lt;td&gt;Conv3x3, stride: 1 kernel: 256,padding: 1&lt;/td&gt;
      &lt;td&gt;ReLU&lt;/td&gt;
      &lt;td&gt;Overlapping Max pooling3x3, stride: 2&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fully-Connected Layer 1&lt;/td&gt;
      &lt;td&gt;4096 neurons&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;ReLU&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;GPU Connection&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fully-Connected Layer 2&lt;/td&gt;
      &lt;td&gt;4096 neurons&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;ReLU&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;GPU Connection&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fully-Connected Layer 3&lt;/td&gt;
      &lt;td&gt;1000 neurons&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Softmax&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;GPU Connection&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;요약하자면 다음과 같다.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;/assets/img/alexnet_network_summary.png&quot; width=&quot;100%&quot; /&gt;
&lt;/center&gt;

&lt;h2 id=&quot;reducing-overfitting&quot;&gt;Reducing Overfitting&lt;/h2&gt;
&lt;p&gt;6000만 개의 파라미터를 사용한다. ILSVRC에서는 1000개의 class를 학습시키는데 image-label mapping을 10 bit로 제약했고, 이는 많은 파라미터를 overfitting 없이 학습 시키기 불충분하다고 했다. 논문에서는 2가지 방법을 통해 overfitting을 막고자 했다.&lt;/p&gt;

&lt;h3 id=&quot;data-augmentation&quot;&gt;Data Augmentation&lt;/h3&gt;
&lt;p&gt;가장 간단하게 overfiitting을 줄이는 방법은 데이터셋을 인공적으로 늘리는 것이다. 
논문에서는 2가지 방법을 사용하여 data augmentation을 했다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;The first form of data augmentation consists of generating image translations and horizontal reflections.&lt;br /&gt;
The second form of data augmentation consists of altering the intensities of the RGB channels in training images. Specifically, we perform PCA on the set of RGB pixel values throughout the ImageNet training set.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;첫번째 방법은 256x256 이미지에서 임의의 부분을 224x224로 자르는 것이다. 그렇게 하면 같은 label을 가진 데이터를 하나의 이미지로 여러 개의 이미지를 만들 수 있게 된다.&lt;/p&gt;

&lt;center&gt;
&lt;img src=&quot;/assets/img/alexnet_augmentation.png&quot; width=&quot;100%&quot; /&gt;
&lt;/center&gt;

&lt;p&gt;256x256 크기의 이미지를 224x224로 crop하고, 수평 반전에도 똑같이 적용하여 데이터가 2048배 증가 시킬 수 있었고, 네트워크의 입력이 224x224인 이유이다.&lt;/p&gt;

&lt;p&gt;두번째 방법은 PCA를 RGB에 적용하여 augmentation을 했다고 한다. PCA(Principal component analysis)는 고차원 데이터를 저차원 데이터로 환원 시키는 방법이라고 한다. 자세한 내용은 좀 더 공부해봐야 할 것 같다. RGB에 PCA를 적용하여 이미지의 eigenvalue $\lambda_{i}$와 eigenvetor $p_{i}$를 구하고, $\lambda_{i}$에 평균이 0이고 표준편차가 0.1인 guassian 분포의 random variable을 곱하여 augmentation을 했다고 한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;center&gt;$I_{xy} = [I_{xy}^{R}, I_{xy}^{G},I_{xy}^{B}] + [p_{1}, p_{2}, p_{3}][\alpha_{1}\lambda_{1}, \alpha_{2}\lambda_{2}, \alpha_{3}\lambda_{3}]^{T}$&lt;/center&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 방법을 통해서 top-1 error rate를 1% 감소하는 효과를 얻었다.&lt;/p&gt;

&lt;h3 id=&quot;dropout&quot;&gt;Dropout&lt;/h3&gt;
&lt;p&gt;Computation cost를 줄이고, overfitting을 줄이기 위해 dropout을 적용했다. dropout은 각 hidden neuron에 값을 0으로 하는 확률을 0.5로 세팅하면서 구현했다고 한다. dropout으로 꺼진 neuron은 forward pass와 back-propagation에 관여하지 않는다. 매 학습마다 꺼지는 neuron은 다르지만, weight는 공유한다고 한다. 논문에서는 모든 neuron을 사용하고, 출력에 0.5를 곱했다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;At test time, we use all the neurons but multiply their outputs by 0.5, which is a reasonable approximation to taking the geometric mean of the predictive distributions produced by the exponentially-many dropout networks.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;center&gt;
&lt;img src=&quot;/assets/img/dropout_2014.png&quot; /&gt;
&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;‘Dropout: A Simple Way to Prevent Neural Networks from Overfitting’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;center&gt;
&lt;img src=&quot;/assets/img/dropout.png&quot; /&gt;
&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;‘Improving neural networks by preventing co-adaptation of feature detectors’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;result&quot;&gt;Result&lt;/h3&gt;

&lt;center&gt;
&lt;img src=&quot;/assets/img/alexnet_result.png&quot; /&gt;
&lt;/center&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&quot;&gt;Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton,’ImageNet Classification with Deep Convolutional Neural Networks’, &lt;em&gt;Neural Information Processing Systems (NIPS)&lt;/em&gt;, 2012&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1207.0580.pdf&quot;&gt;G.E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever and R.R. Salakhutdinov, ‘Improving neural networks by preventing co-adaptation of feature detectors’, 2012&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://dl.acm.org/doi/pdf/10.5555/2627435.2670313&quot;&gt;Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov, ‘Dropout: A Simple Way to Prevent Neural Networks from Overfitting’, vol.15, No.1, 2014&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://stats.stackexchange.com/questions/174295/what-does-the-term-saturating-nonlinearities-mean&quot;&gt;https://stats.stackexchange.com/questions/174295/what-does-the-term-saturating-nonlinearities-mean&lt;/a&gt;&lt;/p&gt;</content><author><name>GitHub User</name><email>dhgudtjr0306@gmail.com</email></author><category term="Review" /><summary type="html">AlexNet “ImageNet Classification with Deep Convolutional Neural Networks”의 저자 Alex Krizhevsky의 이름을 따서 network의 AlexNet이라는 명칭이 붙었다. ILSVRC-2012에서 top-5 test error를 15.3%를 기록 했으며, 26.2%었던 2등과 비교하여 무려 10%가 넘는 격차를 내고 우승했다. ReLU의 대유행을 만들어낸 의미 있는 모델이다.</summary></entry><entry><title type="html">Show Time 개인 정보 처리 방침</title><link href="http://localhost:4000/showtime/2020/04/22/showtime-policy.html" rel="alternate" type="text/html" title="Show Time 개인 정보 처리 방침" /><published>2020-04-22T00:00:00+09:00</published><updated>2020-04-22T00:00:00+09:00</updated><id>http://localhost:4000/showtime/2020/04/22/showtime-policy</id><content type="html" xml:base="http://localhost:4000/showtime/2020/04/22/showtime-policy.html">&lt;p&gt;&lt;strong&gt;1. 개인정보의 처리 목적&lt;/strong&gt; (‘https://hsoh0306.github.io/’이하 ‘Root Developer’) 은(는) 다음의 목적을 위하여 개인정보를 처리하고 있으며, 다음의 목적 이외의 용도로는 이용하지 않습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;고객 가입의사 확인, 고객에 대한 서비스 제공에 따른 본인 식별.인증, 회원자격 유지.관리, 물품 또는 서비스 공급에 따른 금액 결제, 물품 또는 서비스의 공급.배송 등&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2. 개인정보의 처리 및 보유 기간&lt;/strong&gt;
① (‘https://hsoh0306.github.io/’이하 ‘Root Developer’) 은(는) 정보주체로부터 개인정보를 수집할 때 동의 받은 개인정보 보유․이용기간 또는 법령에 따른 개인정보 보유․이용기간 내에서 개인정보를 처리․보유합니다.&lt;/p&gt;

&lt;p&gt;② 구체적인 개인정보 처리 및 보유 기간은 다음과 같습니다.
☞ 아래 예시를 참고하여 개인정보 처리업무와 개인정보 처리업무에 대한 보유기간 및 관련 법령, 근거 등을 기재합니다.
(예시)- 고객 가입 및 관리 : 서비스 이용계약 또는 회원가입 해지시까지, 다만 채권․채무관계 잔존시에는 해당 채권․채무관계 정산시까지- 전자상거래에서의 계약․청약철회, 대금결제, 재화 등 공급기록 : 5년&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. 개인정보의 제3자 제공에 관한 사항&lt;/strong&gt; ① &lt;em&gt;(‘https://hsoh0306.github.io/’이하 ‘Root Developer’)&lt;/em&gt;은(는) 정보주체의 동의, 법률의 특별한 규정 등 개인정보 보호법 제17조 및 제18조에 해당하는 경우에만 개인정보를 제3자에게 제공합니다.&lt;/p&gt;

&lt;p&gt;② &lt;em&gt;(‘https://hsoh0306.github.io/’)&lt;/em&gt;은(는) 다음과 같이 개인정보를 제3자에게 제공하고 있습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;ul&gt;
      &lt;li&gt;개인정보를 제공받는 자 : ShowTime&lt;/li&gt;
      &lt;li&gt;제공받는 자의 개인정보 이용목적 : 없음&lt;/li&gt;
      &lt;li&gt;제공받는 자의 보유.이용기간: 지체없이 파기&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;4. 개인정보처리 위탁&lt;/strong&gt; 
① &lt;em&gt;(‘Root Developer’)&lt;/em&gt;은(는) 원활한 개인정보 업무처리를 위하여 다음과 같이 개인정보 처리업무를 위탁하고 있습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;ul&gt;
      &lt;li&gt;위탁받는 자 (수탁자) : 오형석&lt;/li&gt;
      &lt;li&gt;위탁하는 업무의 내용 : 없음&lt;/li&gt;
      &lt;li&gt;위탁기간 : 지체없이 파기&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;② &lt;em&gt;(‘https://hsoh0306.github.io/’이하 ‘Root Developer’)&lt;/em&gt;은(는) 위탁계약 체결시 개인정보 보호법 제25조에 따라 위탁업무 수행목적 외 개인정보 처리금지, 기술적․관리적 보호조치, 재위탁 제한, 수탁자에 대한 관리․감독, 손해배상 등 책임에 관한 사항을 계약서 등 문서에 명시하고, 수탁자가 개인정보를 안전하게 처리하는지를 감독하고 있습니다.③ 위탁업무의 내용이나 수탁자가 변경될 경우에는 지체없이 본 개인정보 처리방침을 통하여 공개하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. 정보주체와 법정대리인의 권리·의무 및 그 행사방법 이용자는 개인정보주체로써 다음과 같은 권리를 행사할 수 있습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;① 정보주체는 Showtime(‘https://hsoh0306.github.io/’이하 ‘Root Developer) 에 대해 언제든지 다음 각 호의 개인정보 보호 관련 권리를 행사할 수 있습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;개인정보 열람요구&lt;/li&gt;
  &lt;li&gt;오류 등이 있을 경우 정정 요구&lt;/li&gt;
  &lt;li&gt;삭제요구&lt;/li&gt;
  &lt;li&gt;처리정지 요구&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;6. 처리하는 개인정보의 항목 작성&lt;/strong&gt;
① &lt;em&gt;(‘https://hsoh0306.github.io/’이하 ‘Root Developer’)&lt;/em&gt;은(는) 다음의 개인정보 항목을 처리하고 있습니다.&lt;/p&gt;

&lt;p&gt;1&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;필수항목 : 없음&lt;/li&gt;
  &lt;li&gt;선택항목 : 없음&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;7. 개인정보의 파기&lt;/strong&gt; &lt;em&gt;(‘Root Developer’)&lt;/em&gt; &lt;strong&gt;은(는) 원칙적으로 개인정보 처리목적이 달성된 경우에는 지체없이 해당 개인정보를 파기합니다. 파기의 절차, 기한 및 방법은 다음과 같습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;-파기절차
이용자가 입력한 정보는 목적 달성 후 별도의 DB에 옮겨져(종이의 경우 별도의 서류) 내부 방침 및 기타 관련 법령에 따라 일정기간 저장된 후 혹은 즉시 파기됩니다. 이 때, DB로 옮겨진 개인정보는 법률에 의한 경우가 아니고서는 다른 목적으로 이용되지 않습니다.&lt;/p&gt;

&lt;p&gt;-파기기한
이용자의 개인정보는 개인정보의 보유기간이 경과된 경우에는 보유기간의 종료일로부터 5일 이내에, 개인정보의 처리 목적 달성, 해당 서비스의 폐지, 사업의 종료 등 그 개인정보가 불필요하게 되었을 때에는 개인정보의 처리가 불필요한 것으로 인정되는 날로부터 5일 이내에 그 개인정보를 파기합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;8. 개인정보 자동 수집 장치의 설치•운영 및 거부에 관한 사항&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Showtime 은 정보주체의 이용정보를 저장하고 수시로 불러오는 ‘쿠키’를 사용하지 않습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;9. 개인정보 보호책임자 작성&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;① Showtime(‘https://hsoh0306.github.io/’이하 ‘Root Developer) 은(는) 개인정보 처리에 관한 업무를 총괄해서 책임지고, 개인정보 처리와 관련한 정보주체의 불만처리 및 피해구제 등을 위하여 아래와 같이 개인정보 보호책임자를 지정하고 있습니다.&lt;/p&gt;

&lt;p&gt;▶ 개인정보 보호책임자&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;성명 :오형석&lt;/li&gt;
  &lt;li&gt;직책 :대표&lt;/li&gt;
  &lt;li&gt;직급 :대표&lt;/li&gt;
  &lt;li&gt;연락처 :01095347136, dhgudtjr0306@gmail.com,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;※ 개인정보 보호 담당부서로 연결됩니다.&lt;/p&gt;

&lt;p&gt;▶ 개인정보 보호 담당부서&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;부서명 :&lt;/li&gt;
  &lt;li&gt;담당자 :&lt;/li&gt;
  &lt;li&gt;연락처 :&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;② 정보주체께서는 Showtime(‘https://hsoh0306.github.io/’이하 ‘Root Developer) 의 서비스(또는 사업)을 이용하시면서 발생한 모든 개인정보 보호 관련 문의, 불만처리, 피해구제 등에 관한 사항을 개인정보 보호책임자 및 담당부서로 문의하실 수 있습니다. Showtime(‘https://hsoh0306.github.io/’이하 ‘Root Developer) 은(는) 정보주체의 문의에 대해 지체 없이 답변 및 처리해드릴 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;10. 개인정보 처리방침 변경&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;①이 개인정보처리방침은 시행일로부터 적용되며, 법령 및 방침에 따른 변경내용의 추가, 삭제 및 정정이 있는 경우에는 변경사항의 시행 7일 전부터 공지사항을 통하여 고지할 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;11. 개인정보의 안전성 확보 조치&lt;/strong&gt; &lt;em&gt;(‘Root Developer’)&lt;/em&gt; &lt;strong&gt;은(는) 개인정보보호법 제29조에 따라 다음과 같이 안전성 확보에 필요한 기술적/관리적 및 물리적 조치를 하고 있습니다.&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;개인정보에 대한 접근 제한 개인정보를 처리하는 데이터베이스시스템에 대한 접근권한의 부여,변경,말소를 통하여 개인정보에 대한 접근통제를 위하여 필요한 조치를 하고 있으며 침입차단시스템을 이용하여 외부로부터의 무단 접근을 통제하고 있습니다.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>GitHub User</name><email>dhgudtjr0306@gmail.com</email></author><category term="ShowTime" /><summary type="html">1. 개인정보의 처리 목적 (‘https://hsoh0306.github.io/’이하 ‘Root Developer’) 은(는) 다음의 목적을 위하여 개인정보를 처리하고 있으며, 다음의 목적 이외의 용도로는 이용하지 않습니다. 고객 가입의사 확인, 고객에 대한 서비스 제공에 따른 본인 식별.인증, 회원자격 유지.관리, 물품 또는 서비스 공급에 따른 금액 결제, 물품 또는 서비스의 공급.배송 등 2. 개인정보의 처리 및 보유 기간 ① (‘https://hsoh0306.github.io/’이하 ‘Root Developer’) 은(는) 정보주체로부터 개인정보를 수집할 때 동의 받은 개인정보 보유․이용기간 또는 법령에 따른 개인정보 보유․이용기간 내에서 개인정보를 처리․보유합니다.</summary></entry><entry><title type="html">[백준 1700] 멀티탭 스케줄링</title><link href="http://localhost:4000/algorithm/2020/03/11/boj-1700.html" rel="alternate" type="text/html" title="[백준 1700] 멀티탭 스케줄링" /><published>2020-03-11T00:00:00+09:00</published><updated>2020-03-11T00:00:00+09:00</updated><id>http://localhost:4000/algorithm/2020/03/11/boj-1700</id><content type="html" xml:base="http://localhost:4000/algorithm/2020/03/11/boj-1700.html">&lt;p&gt;
사실 이 블로그를 만든 이유는 이 문제때문이다.
며칠전 친구가 갑자기 한번 풀어보라고 문제를 던져주었는데, 그 동안 알고리즘을 소홀히 한 대가로 고통 받았다.
덕분에 알고리즘 공부에 대한 필요성을 회기시켰고, 이거 하나 제대로 못풀었다는 것에 열받아서 기록을 남기기 위해 블로그를 만들었다.
&lt;/p&gt;
&lt;p&gt;
(사실 문제 푼것보다 블로그 만드는거에 더 많은 시간을 썼다.)
&lt;/p&gt;

&lt;p&gt;각설하고 문제를 한번 보자&lt;/p&gt;

&lt;h4&gt;문제&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/1700&quot;&gt;https://www.acmicpc.net/problem/1700&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;
준규라는 친구가 멀티탭에 비해 많은 전기용품을 가지고 있어서 고통받고있다고 한다. 준규를 구원하기 위해서 어떻게 하면 최소한의 교체로 전기용품을 스케줄링할 수 있는지 찾는 것이 우리의 임무다.
&lt;/p&gt;

&lt;h4&gt;입력&lt;/h4&gt;
&lt;div class=&quot;message&quot;&gt;
첫 줄에는 멀티탭 구멍의 개수 N (1 ≤ N ≤ 100)과 전기 용품의 총 사용횟수 K (1 ≤ K ≤ 100)가 정수로 주어진다. 두 번째 줄에는 전기용품의 이름이 K 이하의 자연수로 사용 순서대로 주어진다.각 줄의 모든 정수 사이는 공백문자로 구분되어 있다.
&lt;/div&gt;
&lt;h4&gt;출력&lt;/h4&gt;
&lt;div class=&quot;message&quot;&gt;
하나씩 플러그를 빼는 최소의 횟수를 출력하시오. 
&lt;/div&gt;
&lt;p&gt;
친절한 백준씨는 이 greedy하게 문제를 풀라고 알려주었다. 아직 머리가 굳어 있어 greedy는 자신이 없지만 준규를 위해서 노력해보았다. 좀 지저분하지만 코드를 보고 설명하도록 하겠다.
&lt;/p&gt;
&lt;h4&gt;풀이&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;cp&quot;&gt;#include&amp;lt;iostream&amp;gt;
#include&amp;lt;vector&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Print Status Of Multitap&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;printMultitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;- &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;checkMultitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;algorithm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

		&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;checkMultitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

		&lt;span class=&quot;c1&quot;&gt;// Find Empty&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;c1&quot;&gt;// If Empty Exist&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
			&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

		&lt;span class=&quot;c1&quot;&gt;// Not Empty&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
					&lt;span class=&quot;n&quot;&gt;temp_count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
			&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
			&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
					&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
						&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
							&lt;span class=&quot;n&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
							&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
						&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
						&lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
					&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
				&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
			&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;// Init&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	
	&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;	&lt;span class=&quot;c1&quot;&gt;// -1 : Empty&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;algorithm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multitap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5&gt;
Line: 7-17
&lt;/h5&gt;
&lt;p&gt;함수 이름에서 보다시피 프린트 멀티탭이다. 나도 내 알고리즘이 어떻게 돌아가나 보고 싶어서 만든 함수다. 그냥 멀티탭의 상태를 출력하는 함수다.&lt;/p&gt;
&lt;h5&gt;
Line: 19-26
&lt;/h5&gt;
&lt;p&gt;이 친구는 체크 멀티탭이다. 장치가 멀티탭에 꽂혀있는지 아닌지 확인해주는 함수다. 멀티탭에 있으면 0을 아니면 1을 반환한다.&lt;/p&gt;
&lt;h5&gt;
Line: 28-85
&lt;/h5&gt;
&lt;p&gt;여기가 메인 알고리즘 함수다. 함수가 크니까 나눠서 설명하도록 하겠다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;변수: N: 멀티탭의 크기, K: 사용될 기기들의 갯수, multitap: 멀티탭, input: 기기들 사용 순서&lt;/li&gt;
  &lt;li&gt;30: 최종 결과가 될 친구다. 최소빼는 횟수라고 생각해서 min이라는 이름을 붙여주었다.&lt;/li&gt;
  &lt;li&gt;31: 알고리즘이 시작되는 부분이다. 사용될 기기들을 순서대로 읽기 위한 for문이다.&lt;/li&gt;
  &lt;li&gt;32: 이 친구의 용도는 밑에서 설명하겠다.&lt;/li&gt;
  &lt;li&gt;35-37: 이번 차례의 기기가 멀티탭에 있는지 없는지 궁금한 것은 인지상정이다. 만약에 멀티탭에 있다면 다음 기기로 넘어간다.&lt;/li&gt;
  &lt;li&gt;40-47: 여기까지 왔다는건 이 기기가 멀티탭에 없다는 것이다. 그럼 다음에 무엇이 궁금할까? 나같은 경우엔 멀티탭에 빈자리가 있는지 궁금했다. 멀티탭은 -1로 초기화해놓았고, 다른 기기가 들어올 경우 다시는 -1이 될 일이 없기때문에, -1인지만 확인했다. 멀티탭에 빈자리가 있을 경우 그 자리에 이번 기기의 번호를 기록하고 flag를 세웠다. 32번째 줄에서 태어난 flag가 여기서 사용된다.&lt;/li&gt;
  &lt;li&gt;48-50: flag가 세워졌다는건 스케줄링이 되었다는 것으로 다음으로 넘기면 된다. 아니라면 밑에 줄로 간다.&lt;/li&gt;
  &lt;li&gt;53: 멀티탭에 빈자리가 없다면 안에 있는 누군가를 빼야한다는 것으로 누구를 뺄지에 대한 타겟이다.&lt;/li&gt;
  &lt;li&gt;54: 과거의 흔적이다. 무시하자.&lt;/li&gt;
  &lt;li&gt;55-66: 후보자들끼리 러시안 룰렛을 돌리는 부분이다. 0부터 N까지의 후보자들이 현재(i)부터 끝(K)까지 몇번 나오는지 체크하는데 만약 한번도 나오지 않는다면 바로 타겟이 되는 것이다. 여기서 타겟이 결정되면 81번째 줄로 간다.&lt;/li&gt;
  &lt;li&gt;67-80: 두번째 러시안 룰렛이다. 다들 한번씩은 나온다는 말인데, 그럼 어떻게 타겟을 골라야하는가? 백준님께서 언지하신것처럼 greedy하게 생각해보면, 앞으로 올 순서에서 가장 마지막에 있는 친구가 빠지는 것이 좋은것처럼 보인다. 그럼 0부터 N까지의 후보들이 현재(i)부터 마지막까지(K)에서 최초로 언제 나오는지 확인하고, 가장 늦게 나온 친구를 타겟으로 만들면 되겠다.&lt;/li&gt;
  &lt;li&gt;81: 희생양을 구했으니 현재 들어오는 친구를 그 자리에 입주시키고,&lt;/li&gt;
  &lt;li&gt;82: 카운트를 증가 시킨다.&lt;/li&gt;
  &lt;li&gt;83: 그러고 나면 최종적으로 몇번의 희생이 있었는지 반환한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5&gt;
Line: 87-110
&lt;/h5&gt;
&lt;p&gt;메인 함수는 입력을 받고, 필요한 변수를 초기화한 다음에 알고리즘에 변수를 넘기고, 결과 받고, 양식에 맞춰 출력해주는게 전부다.&lt;/p&gt;

&lt;h4&gt;후기&lt;/h4&gt;
&lt;p&gt;난 greedy가 싫다. 아무튼 싫다. 코드를 다시 읽어보니 내가 짰지만 왜 저렇게 짰는지 이해가 안가는 부분이 많이 보인다. 나름 정리한다고 했음에도 시행착오의 흔적이 남아있다. 그리고 작명센스를 키워야겠다는 필요성을 느꼈다. 이게 내 블로그 첫 포스트인데 글쓰는게 여간 불편한게 아니다. 내일은 짜파게티랑 불닭볶음면 섞어 먹어야겠다.&lt;/p&gt;</content><author><name>GitHub User</name><email>dhgudtjr0306@gmail.com</email></author><category term="Algorithm" /><summary type="html">사실 이 블로그를 만든 이유는 이 문제때문이다. 며칠전 친구가 갑자기 한번 풀어보라고 문제를 던져주었는데, 그 동안 알고리즘을 소홀히 한 대가로 고통 받았다. 덕분에 알고리즘 공부에 대한 필요성을 회기시켰고, 이거 하나 제대로 못풀었다는 것에 열받아서 기록을 남기기 위해 블로그를 만들었다. (사실 문제 푼것보다 블로그 만드는거에 더 많은 시간을 썼다.)</summary></entry><entry><title type="html">Init Blog</title><link href="http://localhost:4000/init/2020/03/11/init-blog.html" rel="alternate" type="text/html" title="Init Blog" /><published>2020-03-11T00:00:00+09:00</published><updated>2020-03-11T00:00:00+09:00</updated><id>http://localhost:4000/init/2020/03/11/init-blog</id><content type="html" xml:base="http://localhost:4000/init/2020/03/11/init-blog.html">&lt;p&gt;
블로그 시작
&lt;/p&gt;</content><author><name>GitHub User</name><email>dhgudtjr0306@gmail.com</email></author><category term="Init" /><summary type="html">블로그 시작</summary></entry></feed>